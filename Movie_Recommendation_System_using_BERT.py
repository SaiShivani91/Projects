# -*- coding: utf-8 -*-
"""Copy of Capstone project 2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vuluOYnmxIy_czqVSlBCbs0IMR4SDHnq

## **MOVIE RECOMMENDATION SYSTEM USING BERT**

**Step 1: Data Collection**
"""

!python3 -m pip install --upgrade kaggle

!kaggle

!cp -R /content/sample_data/kaggle.json /root/.kaggle/

!chmod 600 /root/.kaggle/kaggle.json

!export KAGGLE_USERNAME=        # Give the username of the personal kaggle account
!export KAGGLE_KEY=            # Give the API key of the personal kaggle account and also download the kaggle.json file available in kaggle account

!kaggle datasets download -d rounakbanik/the-movies-dataset

!unzip the-movies-dataset.zip

#Importing the dependencies
import numpy as np
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import pandas as pd

"""**Step 2: Data Preprocessing**"""

df_meta = pd.read_csv("movies_metadata.csv")

df_meta.columns

df_meta.shape

df_meta.head()

df_meta = df_meta[['id', 'genres', 'original_language', 'production_countries', 'tagline', 'original_title', 'adult', 'release_date', 'status']]

df_meta.status.unique()

for i in range(len(df_meta)):
  tmp = df_meta['status'][i]
  if (tmp == "Released"):
    df_meta['status'][i] = "Released"
  else:
    df_meta['status'][i] = ''

import json
import ast

df_meta.genres[0]

for i in range(len(df_meta['genres'])):
  str_tmp = ""
  genre = df_meta['genres'][i]
  genre = genre.replace("\'", "\"")
  json_genre = json.loads(genre)
  for j in range(len(json_genre)):
    str_tmp += (json_genre[j]['name'])+" "
  df_meta['genres'][i] = str_tmp

df_meta['genres'][0]

df_meta['production_countries'][0]

df_meta['production_countries'].replace(np.nan, '', inplace = True)

for i in range(len(df_meta['production_countries'])):
  str_tmp = ""
  country = df_meta['production_countries'][i]
  if (country != ''):
    country = json.dumps(ast.literal_eval(country))
    json_country = json.loads(country)
    print(json_country)
    try:
      for j in range(len(json_country)):
        str_tmp += (json_country[j]['name'])
      print(str_tmp)

      df_meta['production_countries'][i] = str_tmp

    except:
      print(" Error ============> ")
  else:
      print("Blank")

df_meta['production_countries'][0]

df_keyword = pd.read_csv("keywords.csv")

df_keyword.head()

df_keyword.shape

df_keyword['keywords'][0]

for i in range(len(df_keyword['keywords'])):
  str_tmp = ""
  keyword = df_keyword['keywords'][i]
  keyword = json.dumps(ast.literal_eval(keyword))
  json_keyword = json.loads(keyword)
  #print(json_keyword)
  for j in range(len(json_keyword)):
    str_tmp += (json_keyword[j]["name"]) +" "
  #print(str_tmp)

  df_keyword['keywords'][i] = str_tmp

df_keyword['keywords'][0]

df_keyword['keywords'][1]

df_credit = pd.read_csv("credits.csv")

df_credit.shape

df_credit.head()

df_credit = df_credit.rename(columns = ({'crew': 'director'}))

df_credit['cast'][0]

for i in range(len(df_credit['cast'])):
  str_tmp = ""
  credit = df_credit['cast'][i]
  credit = json.dumps(ast.literal_eval(credit))
  json_credit = json.loads(credit)
  # print(json_credit[0]['name'])

  for j in range(len(json_credit)):
    str_tmp += (json_credit[j]['name'])+" "
  # print(str_tmp)

  df_credit['cast'][i] = str_tmp

df_credit['cast'][0]

director = df_credit['director'][0]

print(director)

for i in range(len(df_credit['director'])):
  str_tmp = ""
  director = df_credit['director'][i]
  director = json.dumps(ast.literal_eval(director))
  json_director = json.loads(director)
  #print(json_director)
  for j in range(len(json_director)):
    if json_director[j]['job'] == 'Director':
      str_tmp += (json_director[j]['name']) + " "
      #print(str_tmp)
  df_credit['director'][i] = str_tmp

df_credit['director'][0]

df_meta['id'] = df_meta['id'].astype(str)

df_keyword['id'] = df_keyword['id'].astype(str)

"""**Step 3: Data Integration**"""

df_merge = pd.merge(df_keyword, df_meta, on = 'id', how = 'inner')[['id', 'genres', 'original_language', 'production_countries', 'tagline',
       'original_title', 'keywords', 'adult', 'release_date', 'status']]

df_credit['id'] = df_credit['id'].astype(str)

df_merge_whole = pd.merge(df_merge, df_credit, on='id', how='inner')[['id', 'genres', 'original_language', 'production_countries', 'tagline',
       'original_title', 'keywords', 'cast','director', 'adult', 'release_date', 'status']]

df_merge_whole['keywords'].replace('', np.nan, inplace = True)

df_merge_whole['genres'].replace('', np.nan, inplace=True)

df_merge_whole['original_title'].replace('', np.nan, inplace=True)

df_merge_whole['cast'].replace('', np.nan, inplace=True)

df_merge_whole['director'].replace('', np.nan, inplace=True)

df_merge_whole['release_date'].replace('', np.nan, inplace=True)

df_merge_whole['status'].replace('', np.nan, inplace=True)

df_merge_whole['production_countries'].replace('', np.nan, inplace=True)

df_merge_whole['adult'].replace('', np.nan, inplace=True)

df_merge_whole['tagline'].replace('', np.nan, inplace=True)

df_merge_whole = df_merge_whole.dropna()

df_merge_whole.to_csv("filter_data.csv")

df = pd.read_csv("filter_data.csv")

def combine_features(row):
  return row['original_title']+' '+row['genres']+' '+ row['original_language']+' '+row['director']+' '+row['keywords']+' '+row['cast']+' '+row['tagline']+' '+row['production_countries']

df['combined_value'] = df.apply(combine_features, axis = 1)

df['combined_value'][0]

df['index'] = [i for i in range(len(df))]

"""**Step 4: Exploratory Data Analysis (EDA)**"""

df.shape

df.columns

df.head()

df.isnull().sum()

import matplotlib.pyplot as plt
import seaborn as sns

# Plotting the Distribution of original languages
plt.figure(figsize=(12,6))
sns.countplot(x='original_language', data=df, order=df['original_language'].value_counts().index)
plt.title('Distribution of Original Languages')
plt.xlabel('Original Language')
plt.ylabel('Count')
plt.show()

# Convert release_date to datetime and extract release year
df['release_year'] = pd.to_datetime(df['release_date']).dt.year

# Count the number of movies released each year
release_year_count = df['release_year'].value_counts().sort_index()

# Visualize the highest year of releasing movies
plt.figure(figsize=(23, 10))
sns.barplot(x=release_year_count.index, y=release_year_count.values, palette='viridis')
plt.title('Number of Movies Released Each Year')
plt.xlabel('Release Year')
plt.ylabel('Count')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

df['director'].value_counts()

genre_list = df['genres'].str.split(',')

df['genre_1'] = genre_list.str.get(0)
df['genre_2'] = genre_list.str.get(1)
df['genre_3'] = genre_list.str.get(2)

df.drop('genres',axis =1,inplace =True)

df['genre_1'].value_counts(normalize=True)[:20].plot.bar()



# Functions

#Get title of movie
def title(index):
    return df[df.index == index]["original_title"].values[0]

#Get index of movie
def index(original_title):
    return df[df.original_title == original_title]["index"].values[0]

"""**Step 5: BERT Embeddings**"""

!pip install sentence_transformers

from sentence_transformers import SentenceTransformer
bert = SentenceTransformer('bert-base-nli-mean-tokens')

#Get Embeddings
sentence_embeddings = bert.encode(df['combined_value'].tolist())

"""**Step 6: Cosine Similarity**"""

#Compute similarity
from sklearn.metrics.pairwise import cosine_similarity
similarity = cosine_similarity(sentence_embeddings)

"""**Step 7: Building a Movie Recommendation System**"""

movie_name = 'Toys'

movie_recommendation = sorted(list(enumerate(similarity[index(movie_name)])), key = lambda x:x[1], reverse = True)

print(title(movie_recommendation[1][0]), title(movie_recommendation[2][0]), title(movie_recommendation[3][0]), sep = "\n")